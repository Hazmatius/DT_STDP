{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy\n",
    "import pytorch_STDP\n",
    "import os\n",
    "from pytorch_STDP import RIPLayer\n",
    "from pytorch_STDP import RIPNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class RIPCoder(nn.Module):\n",
    "    def __init__(self, encoder_dims, max_encoder_rate, max_decoder_rate):\n",
    "        super(RIPCoder, self).__init__()\n",
    "        decoder_dims = [i for i in reversed(encoder_dims)]\n",
    "        self.encoder = RIPNetwork(encoder_dims, max_encoder_rate, True, True)\n",
    "        self.decoder = RIPNetwork(decoder_dims, max_decoder_rate, False, True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        code = self.encoder(input)\n",
    "        return self.decoder(code), code\n",
    "\n",
    "\n",
    "folder = '/Users/alexbaranski/Desktop/fig_folder/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vector(f_max, N):\n",
    "    rate = f_max * torch.rand(1, N, requires_grad=True)\n",
    "    phase = torch.zeros(1, N, requires_grad=True)# + torch.randint(0, 3, (1, N))/4\n",
    "    # rate[torch.rand_like(rate) < 0.65] = 0.0\n",
    "    vector = (rate, phase)\n",
    "    return pytorch_STDP.polar_to_cart(vector)\n",
    "\n",
    "def jitter(complex_tensor):\n",
    "    tensor_polar = pytorch_STDP.cart_to_polar(complex_tensor)\n",
    "    rate = tensor_polar[0]\n",
    "    phase = tensor_polar[1]\n",
    "    jitter_tensor = pytorch_STDP.polar_to_cart((rate, phase + torch.rand_like(phase)/20))\n",
    "    return jitter_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor(rates, phases):\n",
    "    rate_tensor = torch.zeros(1, len(rates))\n",
    "    phase_tensor = torch.zeros(1, len(phases))\n",
    "    for i in range(len(rates)):\n",
    "        rate_tensor[0][i] = float(rates[i])\n",
    "        phase_tensor[0][i] = float(phases[i])\n",
    "    return pytorch_STDP.polar_to_cart((rate_tensor, phase_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, dataset, lr, iters):\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    error_hist = list()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        error = torch.zeros(1, requires_grad=True)\n",
    "        for j in range(len(dataset)):\n",
    "            x = dataset[j]\n",
    "            x_hat, code = network.forward(x)\n",
    "            x_hat_polar = pytorch_STDP.cart_to_polar(x_hat)\n",
    "            x_polar = pytorch_STDP.cart_to_polar(x)\n",
    "            error = error + mse.forward(x_hat_polar[0], x_polar[0])\n",
    "        if i % 250 == 0:\n",
    "            print('    {} - ERROR:{:.5f}'.format(i, error.item()))\n",
    "        error_hist.append(error.item())\n",
    "        optimizer.zero_grad()\n",
    "        error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    return error_hist, network\n",
    "\n",
    "def train_network_2(network, lr, iters):\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    error_hist = list()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        error = torch.zeros(1, requires_grad=True)\n",
    "        for j in range(20):\n",
    "            x = make_tensor([np.random.rand()*30], [0])\n",
    "            x_hat, code = network.forward(x)\n",
    "            x_hat_polar = pytorch_STDP.cart_to_polar(x_hat)\n",
    "            x_polar = pytorch_STDP.cart_to_polar(x)\n",
    "            error = error + mse.forward(x_hat_polar[0], x_polar[0])\n",
    "        if i % 250 == 0:\n",
    "            print('    {} - ERROR:{:.5f}'.format(i, error.item()))\n",
    "        error_hist.append(error.item())\n",
    "        optimizer.zero_grad()\n",
    "        error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    return error_hist, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_history(dataset, add_jitter):\n",
    "    encoder_dims = [int(round(i)) for i in np.linspace(32, 8, 6)]\n",
    "    encoder_max_rate = 1\n",
    "    decoder_max_rate = 1\n",
    "    \n",
    "    ripcoder = RIPCoder(encoder_dims, encoder_max_rate, decoder_max_rate)\n",
    "    optimizer = torch.optim.SGD(ripcoder.parameters(), lr=0.1)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    error_hist = list()\n",
    "    \n",
    "    for i in range(10000):\n",
    "        error = torch.zeros(1, requires_grad=True)\n",
    "        for j in range(len(dataset)):\n",
    "            if add_jitter:\n",
    "                x = jitter(dataset[j])\n",
    "            else:\n",
    "                x = dataset[j]\n",
    "            # print(x)\n",
    "            x_hat, code = ripcoder.forward(x)\n",
    "            x_hat_polar = pytorch_STDP.cart_to_polar(x_hat)\n",
    "            x_polar = pytorch_STDP.cart_to_polar(x)\n",
    "            error = error + mse.forward(x_hat_polar[0], x_polar[0])\n",
    "        if i % 100 == 0:\n",
    "            print('    {} - ERROR:{:.5f}'.format(i, error.item()))\n",
    "        error_hist.append(error.item())\n",
    "        optimizer.zero_grad()\n",
    "        error.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    return error_hist, ripcoder\n",
    "        \n",
    "def get_avg_trajectory(traj_list):\n",
    "    return sum([np.array(traj) for traj in traj_list]) / len(traj_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = [0, 5, 10, 15, 20, 25]\n",
    "dataset = [make_tensor([rate], [0]) for rate in rates]\n",
    "# a0 = make_tensor([5], [0])\n",
    "# a1 = make_tensor([10], [0])\n",
    "# a2 = make_tensor([15], [0])\n",
    "# a3 = make_tensor([30], [0])\n",
    "# a2 = random_vector(10, 2)\n",
    "# a1 = pytorch_STDP.polar_to_cart((torch.tensor([[10.0]], requires_grad=True), torch.tensor([[0.0]], requires_grad=True)))\n",
    "# a2 = pytorch_STDP.polar_to_cart((torch.tensor([[15.0]], requires_grad=True), torch.tensor([[0.0]], requires_grad=True)))\n",
    "# a3 = pytorch_STDP.polar_to_cart((torch.tensor([[20.0]], requires_grad=True), torch.tensor([[0.0]], requires_grad=True)))\n",
    "\n",
    "# dataset = [a0, a1, a2, a3]\n",
    "# print(a1)\n",
    "# print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 - ERROR:35.04125\n",
      "    250 - ERROR:10.96294\n",
      "    500 - ERROR:18.10490\n",
      "    750 - ERROR:18.69323\n"
     ]
    }
   ],
   "source": [
    "# small_ripcoder = RIPCoder([1, 3], 1, 40)\n",
    "# print(small_ripcoder)\n",
    "error_hist, small_ripcoder = train_network_2(small_ripcoder, 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000, 9.121\n",
      "\n",
      "\n",
      "1.000, 0.223\n",
      "1.000, 0.078\n",
      "1.000, 0.578\n"
     ]
    }
   ],
   "source": [
    "data_element = a1\n",
    "\n",
    "x_hat, x_code = small_ripcoder(data_element)\n",
    "polar_a1 = pytorch_STDP.cart_to_polar(data_element)\n",
    "polar_x_hat = pytorch_STDP.cart_to_polar(x_hat)\n",
    "polar_x_code = pytorch_STDP.cart_to_polar(x_code)\n",
    "\n",
    "for i in range(torch.numel(a1[0])):\n",
    "    print('{:.3f}, {:.3f}'.format(polar_a1[0][0][i].item(), polar_x_hat[0][0][i].item()))\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for i in range(torch.numel(polar_x_code[0])):\n",
    "    print('{:.3f}, {:.3f}'.format(polar_x_code[0][0][i].item(), polar_x_code[1][0][i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = np.arange(0, 51, 0.1)\n",
    "rates_hat = np.zeros_like(rates)\n",
    "\n",
    "for index, rate in enumerate(rates):\n",
    "    data_element = make_tensor([rate], [0])\n",
    "    x_hat, x_code = small_ripcoder(data_element)\n",
    "    polar_a1 = pytorch_STDP.cart_to_polar(data_element)\n",
    "    polar_x_hat = pytorch_STDP.cart_to_polar(x_hat)\n",
    "    polar_x_code = pytorch_STDP.cart_to_polar(x_code)\n",
    "    # print(polar_x_hat)\n",
    "    rates_hat[index] = polar_x_hat[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbe1b9d550>]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rates, rates_hat)\n",
    "plt.plot(rates, rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.5644]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-42.7981], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(small_ripcoder.encoder.network[0].affine.linear.weight)\n",
    "print(small_ripcoder.encoder.network[0].affine.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no jitter\n",
      "    0 - ERROR:1.76073\n",
      "    100 - ERROR:0.79645\n",
      "    200 - ERROR:0.62446\n",
      "    300 - ERROR:0.66268\n",
      "    400 - ERROR:0.46898\n",
      "    500 - ERROR:0.41050\n",
      "    600 - ERROR:0.83894\n",
      "    700 - ERROR:0.58064\n",
      "    800 - ERROR:0.92368\n",
      "    900 - ERROR:0.67692\n",
      "    1000 - ERROR:0.35107\n",
      "    1100 - ERROR:0.32926\n",
      "    1200 - ERROR:0.26332\n",
      "    1300 - ERROR:0.20385\n",
      "    1400 - ERROR:0.86522\n",
      "    1500 - ERROR:0.74534\n",
      "    1600 - ERROR:0.59362\n",
      "    1700 - ERROR:0.37474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-8d3a9e2d557a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no jitter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0merror_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_error_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mwithout_jitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwithout_jitter_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-83e3a68cbf9f>\u001b[0m in \u001b[0;36mget_error_history\u001b[0;34m(dataset, add_jitter)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0merror_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripcoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DT_STDP/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DT_STDP/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "without_jitter = list()\n",
    "with_jitter = list()\n",
    "without_jitter_models = list()\n",
    "with_jitter_models = list()\n",
    "\n",
    "dataset = list()\n",
    "for i in range(10):\n",
    "    dataset.append(random_vector(1, 32))\n",
    "\n",
    "for i in range(1):\n",
    "    print('no jitter')\n",
    "    error_hist, ripnet = get_error_history(dataset, False)\n",
    "    without_jitter.append(error_hist)\n",
    "    without_jitter_models.append(ripnet)\n",
    "    # without_jitter.append(get_error_history(dataset, False))\n",
    "    \n",
    "#     print('jitter')\n",
    "#     error_hist, ripnet = get_error_history(dataset, True)\n",
    "#     with_jitter.append(error_hist)\n",
    "#     with_jitter_models.append(ripnet)\n",
    "    \n",
    "    # with_jitter.append(get_error_history(dataset, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056 : 0.054\n",
      "0.784 : 0.777\n",
      "0.373 : 0.375\n",
      "0.634 : 0.637\n",
      "0.192 : 0.200\n",
      "0.088 : 0.093\n",
      "0.207 : 0.207\n",
      "0.197 : 0.196\n",
      "0.244 : 0.241\n",
      "0.564 : 0.566\n",
      "0.296 : 0.307\n",
      "0.171 : 0.174\n",
      "0.463 : 0.462\n",
      "0.702 : 0.704\n",
      "0.648 : 0.650\n",
      "0.577 : 0.577\n",
      "0.074 : 0.073\n",
      "0.756 : 0.763\n",
      "0.545 : 0.542\n",
      "0.591 : 0.591\n",
      "0.182 : 0.182\n",
      "0.365 : 0.367\n",
      "0.853 : 0.850\n",
      "0.006 : 0.009\n",
      "0.461 : 0.460\n",
      "0.751 : 0.757\n",
      "0.982 : 0.967\n",
      "0.630 : 0.630\n",
      "0.239 : 0.247\n",
      "0.980 : 0.954\n",
      "0.771 : 0.774\n",
      "0.222 : 0.227\n",
      "\n",
      "\n",
      "\n",
      "0.260\n",
      "0.527\n",
      "0.840\n",
      "0.738\n",
      "0.710\n",
      "0.235\n",
      "0.027\n",
      "0.085\n"
     ]
    }
   ],
   "source": [
    "index = 9\n",
    "x = dataset[index]\n",
    "y, c = ripnet(x)\n",
    "x = pytorch_STDP.cart_to_polar(x)\n",
    "y = pytorch_STDP.cart_to_polar(y)\n",
    "c = pytorch_STDP.cart_to_polar(c)\n",
    "\n",
    "for i in range(torch.numel(x[0])):\n",
    "    print('{:.3f} : {:.3f}'.format(x[0][0][i].item(), y[0][0][i].item()))\n",
    "    \n",
    "print(2 * '\\n')\n",
    "\n",
    "for i in range(torch.numel(c[0])):\n",
    "    \n",
    "    print('{:.3f}'.format(c[1][0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_without_jitter = get_avg_trajectory(without_jitter)\n",
    "mean_with_jitter = get_avg_trajectory(with_jitter)\n",
    "\n",
    "jitter_fig = plt.figure()\n",
    "# plt.plot(mean_without_jitter)\n",
    "# plt.plot(with_jitter[0])\n",
    "# plt.plot(with_jitter[1])\n",
    "# plt.plot(with_jitter[2])\n",
    "plt.plot(mean_with_jitter)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Training error')\n",
    "plt.title('Denoising autoencoder')\n",
    "\n",
    "plt.savefig('/Users/alexbaranski/Desktop/fig_folder/DAE_error_2.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = list()\n",
    "for j in range(len(dataset)):\n",
    "    x = dataset[j]\n",
    "    x_hat, code = ripcoder.forward(x)\n",
    "    code_polar = pytorch_STDP.cart_to_polar(code)\n",
    "    phases\n",
    "    # print(code_polar)\n",
    "\n",
    "f1 = plt.figure()\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.plot(error_hist)\n",
    "ax1.set_title('Error')\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "plt.plot(entropy_hist)\n",
    "ax2.set_title('Encoding Phase Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f2 = plt.figure(figsize=(10,5))\n",
    "colors = [[0,0,0],\n",
    "          [1,0,0],\n",
    "          [0,1,0],\n",
    "          [0,0,1],\n",
    "          [1,1,0],\n",
    "          [1,0,1],\n",
    "          [0,1,1],\n",
    "          [.5,.5,0],\n",
    "          [.5,0,.5],\n",
    "          [0,.5,.5]\n",
    "         ]\n",
    "for i, d in enumerate(dataset):\n",
    "    x_hat, code = ripcoder.forward(d)\n",
    "    code_polar = pytorch_STDP.cart_to_polar(code)\n",
    "    phases = code_polar[1].detach().numpy()\n",
    "    # rates = code_polar[0].detach().numpy()\n",
    "    phases = [2*np.pi*p for p in phases[0]]\n",
    "    # print(i, phases)\n",
    "    ax = plt.subplot(2, 5, i+1, polar=True)\n",
    "    for phase in phases:\n",
    "        # x = [0, np.cos(phase)]\n",
    "        # y = [0, np.sin(phase)]\n",
    "        \n",
    "        theta = [0, 360 * phase / (2 * np.pi)]\n",
    "        r = [0, 1]\n",
    "        \n",
    "        # x = [0, np.cos(np.mod(phase, np.pi))]\n",
    "        # y = [0, np.sin(np.mod(phase, np.pi))]\n",
    "        plt.plot(theta,r,color=colors[i])\n",
    "    # mod_phases = \n",
    "    ax.set_aspect(1)\n",
    "    # ax.set_xlim([-1,1])\n",
    "    # ax.set_ylim([-1,1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DT_STDP",
   "language": "python",
   "name": "dt_stdp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
